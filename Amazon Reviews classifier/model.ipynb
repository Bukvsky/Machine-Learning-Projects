{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-17T21:34:40.909180Z",
     "start_time": "2025-08-17T21:34:40.475734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kagglehub\n",
    "\n",
    "# List all files in the dataset\n",
    "dataset_path = kagglehub.dataset_download(\"kritanjalijain/amazon-reviews\")\n",
    "print(dataset_path)  # See where itâ€™s stored locally\n",
    "\n",
    "import os\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for f in files:\n",
    "        print(f)\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibuko\\.cache\\kagglehub\\datasets\\kritanjalijain\\amazon-reviews\\versions\\2\n",
      "amazon_review_polarity_csv.tgz\n",
      "test.csv\n",
      "train.csv\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T21:34:42.898069Z",
     "start_time": "2025-08-17T21:34:42.894072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import keras_nlp"
   ],
   "id": "723f4811f5b5df70",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T21:34:44.204791Z",
     "start_time": "2025-08-17T21:34:44.198184Z"
    }
   },
   "cell_type": "code",
   "source": "print('\\\\'.join(dataset_path.split('\\\\')[:-1])+'\\\\train.csv')",
   "id": "cf9811702dc14c08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibuko\\.cache\\kagglehub\\datasets\\kritanjalijain\\amazon-reviews\\versions\\train.csv\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T21:35:02.614076Z",
     "start_time": "2025-08-17T21:34:45.061723Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv('\\\\'.join(dataset_path.split('\\\\')[:-1])+'\\\\2\\\\train.csv', header=None)",
   "id": "efdafba9b0ca537c",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T21:35:02.637190Z",
     "start_time": "2025-08-17T21:35:02.628812Z"
    }
   },
   "cell_type": "code",
   "source": "df.columns",
   "id": "59907f7489173282",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([0, 1, 2], dtype='int64')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T21:35:02.669265Z",
     "start_time": "2025-08-17T21:35:02.658660Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "e9cf1a6830fb4f42",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   0                                                  1  \\\n",
       "0  2                     Stuning even for the non-gamer   \n",
       "1  2              The best soundtrack ever to anything.   \n",
       "2  2                                           Amazing!   \n",
       "3  2                               Excellent Soundtrack   \n",
       "4  2  Remember, Pull Your Jaw Off The Floor After He...   \n",
       "\n",
       "                                                   2  \n",
       "0  This sound track was beautiful! It paints the ...  \n",
       "1  I'm reading a lot of reviews saying that this ...  \n",
       "2  This soundtrack is my favorite music of all ti...  \n",
       "3  I truly like this soundtrack and I enjoy video...  \n",
       "4  If you've played the game, you know how divine...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Stuning even for the non-gamer</td>\n",
       "      <td>This sound track was beautiful! It paints the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The best soundtrack ever to anything.</td>\n",
       "      <td>I'm reading a lot of reviews saying that this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Amazing!</td>\n",
       "      <td>This soundtrack is my favorite music of all ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Excellent Soundtrack</td>\n",
       "      <td>I truly like this soundtrack and I enjoy video...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>If you've played the game, you know how divine...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T21:35:24.614171Z",
     "start_time": "2025-08-17T21:35:22.567265Z"
    }
   },
   "cell_type": "code",
   "source": "val_df = pd.read_csv('\\\\'.join(dataset_path.split('\\\\')[:-1])+'\\\\2\\\\test.csv', header=None)\n",
   "id": "c70ffe5a67d6c6f9",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T21:35:35.605967Z",
     "start_time": "2025-08-17T21:35:35.600899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.rename(columns={0:'polarity', 1:'title',2:'text'}, inplace=True)\n",
    "val_df.rename(columns={0:'polarity', 1:'title',2:'text'}, inplace=True)\n"
   ],
   "id": "f11707166e03cf91",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T21:35:39.730068Z",
     "start_time": "2025-08-17T21:35:38.452497Z"
    }
   },
   "cell_type": "code",
   "source": "df.info(memory_usage='deep')",
   "id": "3874611df2859a5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3600000 entries, 0 to 3599999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Dtype \n",
      "---  ------    ----- \n",
      " 0   polarity  int64 \n",
      " 1   title     object\n",
      " 2   text      object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.8 GB\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T21:35:42.055885Z",
     "start_time": "2025-08-17T21:35:41.634676Z"
    }
   },
   "cell_type": "code",
   "source": "len(df['text'].max())",
   "id": "6037c1238338cc9f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T21:36:26.696668Z",
     "start_time": "2025-08-17T21:36:23.274122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['combined_text'] = df['title'] + ' ' + df['text']\n",
    "val_df['combined_text'] = val_df['title'] + ' ' + val_df['text']"
   ],
   "id": "e468e44b88eac82f",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T21:38:20.706890Z",
     "start_time": "2025-08-17T21:38:18.483169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df['combined_text'],\n",
    "    df['polarity'],\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=df['polarity']\n",
    ")\n",
    "\n",
    "# Test set\n",
    "X_test = df['combined_text']\n",
    "y_test = df['polarity']\n",
    "\n",
    "print(f\"Training: {len(X_train)}\")\n",
    "print(f\"Validation: {len(X_val)}\")\n",
    "print(f\"Test: {len(X_test)}\")"
   ],
   "id": "f5ebe5991392bb0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 3240000\n",
      "Validation: 360000\n",
      "Test: 3600000\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T21:26:19.871157Z",
     "start_time": "2025-08-17T21:26:19.867156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data pipeline and padding parameters\n",
    "SHUFFLE_BUFFER_SIZE = 5000\n",
    "PREFETCH_BUFFER_SIZE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 64\n",
    "PADDING_TYPE = 'pre'\n",
    "TRUNC_TYPE = 'post'\n",
    "VOCAB_SIZE = 20000\n",
    "SEQ_LEN = 128\n"
   ],
   "id": "c1dfec61adf781e3",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T21:31:50.226524Z",
     "start_time": "2025-08-17T21:31:50.187737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "print(tf.__version__)\n",
    "print(text.__version__)\n"
   ],
   "id": "8ccd63c4cb3b671c",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_text'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[15]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtensorflow\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtf\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtensorflow_text\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtext\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28mprint\u001B[39m(tf.__version__)\n\u001B[32m      4\u001B[39m \u001B[38;5;28mprint\u001B[39m(text.__version__)\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'tensorflow_text'"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T21:30:35.320497Z",
     "start_time": "2025-08-17T21:30:35.247679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
    "    vocabulary_size=VOCAB_SIZE,\n",
    "    sequence_length=SEQ_LEN,\n",
    ")\n"
   ],
   "id": "917190788d54cc88",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "WordPieceTokenizer requires `tensorflow` and `tensorflow-text` for text processing. Run `pip install tensorflow-text` to install both packages or visit https://www.tensorflow.org/install\n\nIf `tensorflow-text` is already installed, try importing it in a clean python session. Your installation may have errors.\n\nKerasHub uses `tf.data` and `tensorflow-text` to preprocess text on all Keras backends. If you are running on Jax or Torch, this installation does not need GPU support.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m tokenizer = \u001B[43mkeras_nlp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtokenizers\u001B[49m\u001B[43m.\u001B[49m\u001B[43mWordPieceTokenizer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvocabulary_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mVOCAB_SIZE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[43msequence_length\u001B[49m\u001B[43m=\u001B[49m\u001B[43mSEQ_LEN\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Programowanie\\Python\\Google tensorflow\\.venv\\Lib\\site-packages\\keras_hub\\src\\tokenizers\\word_piece_tokenizer.py:342\u001B[39m, in \u001B[36mWordPieceTokenizer.__init__\u001B[39m\u001B[34m(self, vocabulary, sequence_length, lowercase, strip_accents, split, split_on_cjk, suffix_indicator, oov_token, special_tokens, special_tokens_in_strings, dtype, **kwargs)\u001B[39m\n\u001B[32m    336\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_int_dtype(dtype) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_string_dtype(dtype):\n\u001B[32m    337\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    338\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mOutput dtype must be an integer type or a string. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    339\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mReceived: dtype=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    340\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m342\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    343\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m oov_token \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    344\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33m`oov_token` cannot be None.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Programowanie\\Python\\Google tensorflow\\.venv\\Lib\\site-packages\\keras_hub\\src\\tokenizers\\tokenizer.py:70\u001B[39m, in \u001B[36mTokenizer.__init__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m     68\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **kwargs):\n\u001B[32m     69\u001B[39m     \u001B[38;5;28mself\u001B[39m.config_file = kwargs.pop(\u001B[33m\"\u001B[39m\u001B[33mconfig_file\u001B[39m\u001B[33m\"\u001B[39m, TOKENIZER_CONFIG_FILE)\n\u001B[32m---> \u001B[39m\u001B[32m70\u001B[39m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     71\u001B[39m     \u001B[38;5;28mself\u001B[39m.file_assets = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Programowanie\\Python\\Google tensorflow\\.venv\\Lib\\site-packages\\keras_hub\\src\\layers\\preprocessing\\preprocessing_layer.py:10\u001B[39m, in \u001B[36mPreprocessingLayer.__init__\u001B[39m\u001B[34m(self, **kwargs)\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, **kwargs):\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m     \u001B[43massert_tf_libs_installed\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[34;43m__class__\u001B[39;49m\u001B[43m.\u001B[49m\u001B[34;43m__name__\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     11\u001B[39m     \u001B[38;5;28msuper\u001B[39m().\u001B[34m__init__\u001B[39m(**kwargs)\n\u001B[32m     12\u001B[39m     \u001B[38;5;66;03m# Don't convert inputs (we want tf tensors not backend tensors).\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Programowanie\\Python\\Google tensorflow\\.venv\\Lib\\site-packages\\keras_hub\\src\\utils\\tensor_utils.py:262\u001B[39m, in \u001B[36massert_tf_libs_installed\u001B[39m\u001B[34m(symbol_name)\u001B[39m\n\u001B[32m    260\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34massert_tf_libs_installed\u001B[39m(symbol_name):\n\u001B[32m    261\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m tf_text \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m tf \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m262\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[32m    263\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msymbol_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m requires `tensorflow` and `tensorflow-text` for \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    264\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mtext processing. Run `pip install tensorflow-text` to install \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    265\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mboth packages or visit https://www.tensorflow.org/install\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    266\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mIf `tensorflow-text` is already installed, try importing it \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    267\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33min a clean python session. Your installation may have errors.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    268\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mKerasHub uses `tf.data` and `tensorflow-text` to preprocess text \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    269\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mon all Keras backends. If you are running on Jax or Torch, this \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    270\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33minstallation does not need GPU support.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    271\u001B[39m         )\n",
      "\u001B[31mImportError\u001B[39m: WordPieceTokenizer requires `tensorflow` and `tensorflow-text` for text processing. Run `pip install tensorflow-text` to install both packages or visit https://www.tensorflow.org/install\n\nIf `tensorflow-text` is already installed, try importing it in a clean python session. Your installation may have errors.\n\nKerasHub uses `tf.data` and `tensorflow-text` to preprocess text on all Keras backends. If you are running on Jax or Torch, this installation does not need GPU support."
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8023a39b2772853c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
